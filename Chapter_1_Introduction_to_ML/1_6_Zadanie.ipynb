{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJcp+vPb8Zxfj/Y/OR5MXO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grzegorzbury/Wprowadzenie-do-Machine-Learningu-z-Pythonem-Tasks/blob/main/Chapter_1_Introduction_to_ML/1_6_Zadanie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ft6z-sOkzLWh",
        "outputId": "8114ca76-2e43-4555-8115-95161e8fafd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WINE] Score for the TRAIN:  DecisionTreeRegressor() 1.0\n",
            "[WINE] Score for the TEST:  DecisionTreeRegressor() 0.8353658536585366\n",
            "[WINE] Score for the TRAIN:  DecisionTreeClassifier() 1.0\n",
            "[WINE] Score for the TEST:  DecisionTreeClassifier() 0.9722222222222222\n",
            "[WINE] Score for the TRAIN:  RandomForestClassifier() 1.0\n",
            "[WINE] Score for the TEST:  RandomForestClassifier() 0.9722222222222222\n",
            "[WINE] Score for the TRAIN:  LinearRegression() 0.919071553176753\n",
            "[WINE] Score for the TEST:  LinearRegression() 0.7643759153956304\n",
            "[WINE] Score for the TRAIN:  RandomForestRegressor() 0.9929051761846902\n",
            "[WINE] Score for the TEST:  RandomForestRegressor() 0.899644512195122\n",
            "true values  DecisionTreeRegressor() [151.  75. 141. 206. 135.  97. 138.  63. 110. 310.]\n",
            "predicted    DecisionTreeRegressor() [257. 306. 202. 202.  52. 277.  90. 212. 110. 220.]\n",
            "[DIABETES] Score for the TRAIN:  DecisionTreeRegressor() 1.0\n",
            "[DIABETES] Score for the TEST:  DecisionTreeRegressor() -0.4140435926556274\n",
            "true values  DecisionTreeClassifier() [151.  75. 141. 206. 135.  97. 138.  63. 110. 310.]\n",
            "predicted    DecisionTreeClassifier() [275. 197. 124. 293. 257. 173.  65. 178. 200. 173.]\n",
            "[DIABETES] Score for the TRAIN:  DecisionTreeClassifier() 1.0\n",
            "[DIABETES] Score for the TEST:  DecisionTreeClassifier() 0.0\n",
            "true values  RandomForestClassifier() [151.  75. 141. 206. 135.  97. 138.  63. 110. 310.]\n",
            "predicted    RandomForestClassifier() [336. 242. 118. 160.  48. 275. 118. 197.  95. 265.]\n",
            "[DIABETES] Score for the TRAIN:  RandomForestClassifier() 1.0\n",
            "[DIABETES] Score for the TEST:  RandomForestClassifier() 0.02247191011235955\n",
            "true values  LinearRegression() [151.  75. 141. 206. 135.  97. 138.  63. 110. 310.]\n",
            "predicted    LinearRegression() [238.47145247 248.93170646 164.05404165 120.30794355 187.42422054\n",
            " 259.04865002 113.55556372 188.07597044 149.49663441 236.01099949]\n",
            "[DIABETES] Score for the TRAIN:  LinearRegression() 0.5539285357415583\n",
            "[DIABETES] Score for the TEST:  LinearRegression() 0.33222203269065176\n",
            "true values  RandomForestRegressor() [151.  75. 141. 206. 135.  97. 138.  63. 110. 310.]\n",
            "predicted    RandomForestRegressor() [250.69 240.17 178.87 100.75 183.65 261.6   88.88 215.06 140.33 245.71]\n",
            "[DIABETES] Score for the TRAIN:  RandomForestRegressor() 0.9209977638824097\n",
            "[DIABETES] Score for the TEST:  RandomForestRegressor() 0.29177547419624295\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "### Tworzenie klasyfikatorów\n",
        "\n",
        "clf_tree_reg = DecisionTreeRegressor()\n",
        "clf_tree_cls = DecisionTreeClassifier()\n",
        "clf_rfor_cls = RandomForestClassifier()\n",
        "clf_rfor_reg = RandomForestRegressor()\n",
        "clf_line_reg = LinearRegression()\n",
        "\n",
        "### Definicja funckji wczytywania danych z datesets\n",
        "\n",
        "def import_wine_data():\n",
        "    \"\"\"\n",
        "        Zwraca:\n",
        "            X - dane\n",
        "            y - target labels\n",
        "            target_names - labels do tego zbioru\n",
        "    \"\"\"\n",
        "    wine_data = load_wine()\n",
        "    X, y = wine_data['data'], wine_data['target']\n",
        "    return X, y\n",
        "\n",
        "def import_V():\n",
        "    \"\"\"\n",
        "        Zwraca:\n",
        "            X - dane\n",
        "            y - target labels\n",
        "            target_names - labels do tego zbioru\n",
        "    \"\"\"\n",
        "    diabetes = load_diabetes()\n",
        "    X, y = diabetes['data'], diabetes['target']\n",
        "    return X, y\n",
        "\n",
        "Xw, yw = import_wine_data()\n",
        "Xd, yd = import_V()\n",
        "\n",
        "Xw_train, Xw_test, yw_train, yw_test = train_test_split(Xw, yw, test_size=0.20, random_state=0)\n",
        "Xd_train, Xd_test, yd_train, yd_test = train_test_split(Xd, yd, test_size=0.20, random_state=0)\n",
        "\n",
        "\n",
        "clf_list = [clf_tree_reg, clf_tree_cls, clf_rfor_cls, clf_line_reg,clf_rfor_reg]\n",
        "\n",
        "# Test dla wine_dataset\n",
        "for clf in clf_list:\n",
        "    clf.fit(Xw_train, yw_train)\n",
        "    \n",
        "    yw_pred = clf.predict(Xw_test)\n",
        "\n",
        " #   print(\"true values \", str(clf), yw[:10])\n",
        " #   print(\"predicted   \", str(clf), yw_pred[:10])\n",
        "    clf_score_train = clf.score(Xw_train, yw_train)\n",
        "    print(\"[WINE] Score for the TRAIN: \", str(clf), clf_score_train)\n",
        "\n",
        "    clf_score_test = clf.score(Xw_test, yw_test)\n",
        "    print(\"[WINE] Score for the TEST: \", str(clf), clf_score_test)\n",
        "\n",
        "# Test dla digits_dataset\n",
        "for clf in clf_list:\n",
        "    clf.fit(Xd_train, yd_train)\n",
        "    \n",
        "    yd_pred = clf.predict(Xd_test)\n",
        "\n",
        "    print(\"true values \", str(clf), yd[:10])\n",
        "    print(\"predicted   \", str(clf), yd_pred[:10])\n",
        "\n",
        "    clf_score_train = clf.score(Xd_train, yd_train)\n",
        "    print(\"[DIABETES] Score for the TRAIN: \", str(clf), clf_score_train)\n",
        "\n",
        "    clf_score_test = clf.score(Xd_test, yd_test)\n",
        "    print(\"[DIABETES] Score for the TEST: \", str(clf), clf_score_test)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do zadania załadowano dwa zbiory danych (1) wina (2) diabetycy. Zbiór wina to zbiór danych do klasyfikacji natomiast zbiór diabetyków odnosi się do przewidywania wartości (regresja). Wybrano 5 klasyfikatorów. Trzy z nich odnoszą się do regresji (DecisionTreeRegressor, RandomForestRegressor, LinearRegression) a dwa do klasyfikacji (RandomForestClassifier, DecisionTreeClassifier).\n",
        "\n",
        "Taki wybór został dokonany w założeniu, że klasyfikatory zorientowane na regresję, przyniosą lepsze wyniki dla danych odnośnie do diabetyków, a klasyfikatory zorientowane na klasyfikację dadzą poprawne wyniki jedynie dla zbiorów opisującego wina.\n",
        "\n",
        "Jednakże, założenia nie zostały całkowicie potwierdzone. Dla zbioru win wyróżnimy trzy klasyfikatory, dla których występuje overfitting dla danych uczących (DecisionTreeRegressor, DecisionTreeClassifier, RandomForestClassifier, ponieważ score = 1 co daje fałszywie wysoką skuteczność przewidywania dla danych treningowych (Testowano różny stosunek podziału; 0.20 oraz 0.33). Algorytm RandomForestRegressor również zbyt dobrze dopasowuje się do danych treningowych (score = 0.99). Podsumowując, dla zbioru win, najrozsądniejsze wyniki daje algorytm LinearRegression, ponieważ score dla treningowych i testowanych danych wynosi odpowiednio 0.92 i 0.76.\n",
        "\n",
        "Dla danych o diabetykach wybrane modele nie są skuteczne. Po pierwsze algorytmy: DecisionTreeRegressor, DecisionTreeClassifier oraz RandomForestClassifier fałszywie dopasowują się do danych treningowych (score = 1) a następnie wykazują ekstremalnie niską jakość równą 0.0 lub 0.02. Algorytm DecisionTreeRegressor kompletnie nie nadaje się do opisu zbioru danych (nie da się wpasować danych w model), ponieważ score daje wynik negatywny. Algorytm LinearRegression daje wynik wyłącznie 0.55 dla danych treningowych, co owocuje w jakości danych testowych na poziomie 0.33. Rozsądny wynik dla danych uczących daje algorytm RandomForestRegressor (score = 0.92), jednak wynik dla danych testowych (0.29) pokazuje, że model nie jest skuteczny nawet w 30%.\n"
      ],
      "metadata": {
        "id": "FmRZrLo--3fS"
      }
    }
  ]
}